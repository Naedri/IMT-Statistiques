---
title: "UE Probabilité et Statistique - Mathématiques"
subtitle: "Devoir Maison n°8"
author: "Vincent Escoffier, Adrien Jallais, Théo Martel, Louis Muzellec."
place: "IMT-Atlantique - FIL A2"
date: "`r format(Sys.time(), '%d %B %Y')`"
knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding, output_dir = "../output") })
output:
  pdf_document: 
    latex_engine: xelatex  # More modern PDF typesetting engine
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE, tidy.opts = list(width.cutoff = 79),
  tidy = TRUE, fig.width = 6, fig.height = 6,
  warning = FALSE, message = FALSE
)
```

## Préparation de l'environnement

R et Rstudio seront utilisés pour la rédaction de ce DM, ainsi que les packagessuivants :

```{r packages_loading, results='hide'}
library(readr)
library(dplyr)
library(ggplot2)
```

\newpage

# Exercice 1

```{r 1_cleaning, echo=FALSE, results='hide'}
rm(list = ls(all = TRUE))
data.frame(unlist("all"))
```

## Contexte

Soit $X$, la variable aléatoire représentant le nombre d'accidents par assuré. $X$ est une variables aléatoire discrète. Il est admis que l'occurence des sinistres $X$ suit une loi de Poisson pour laquelle on recherche le paramètre inconnu $\lambda$.
Le modèle d'échantillonage de nos données est le suivant : $(\mathbb{N}, (\mathscr{P}_{\lambda})_{\lambda>0})^{n}$.

### Description des données

```{r 1_data_import, echo=FALSE, results='hide'}
# On importe les données avec la commande suivante
d1 <- read_delim("../data/donnees.exo1.csv", 
    delim = ";", escape_double = FALSE, trim_ws = TRUE, show_col_types = FALSE)
```

L'effectif de l'échantillon est de `r dim(d1)[1]`. Celui-ci peut donc être considéré de grande taille.

Les indicateurs et le graphe suivant résument la dispersion de nos données :

```{r 1_data_description, echo=FALSE, fig.asp = .63}
summary(d1$sinistre)
ggplot(d1, aes(x=sinistre)) + geom_bar()
```

A partir de $\overline{X} =$ `r dim(d1)[1]`, on a $n \overline{X}_{n} =$ `r dim(d1)[1]*mean(d1$sinistre)`.

## Intervalle de confiance ($IC$) asymptotique pour $\lambda$

Comme ???, on peut approximer la loi de Poisson par une loi Normale centrée réduite $N(0,1)$ par : 

\[\frac{\sqrt{n}(Xn - \lambda)}{\sqrt{Xn}} \leadsto N(0,1)\]

Avec cette approximation, on peut en déduire un intervalle de confiance ($IC$) asymptotique (car $n =$ `r dim(d1)[1]` $< 100$).

### 1. Calcul d'un interval de confiance asymptotique unilatéral gauche de niveau 95% pour $\lambda$ ($IC_g$)

On obtient un $IC$ tel que : 

\[IC^{1-\alpha \text{ asymp }}_{\underline{X}_{n}}(\lambda) =  \left[\overline{X}_{n} - Z_{1 - \frac{\alpha}{2}} \times \sqrt{\frac{\overline{X}_{n}}{n}} <  \lambda \right] \space : (1)\]
\[(1) \space \Leftrightarrow IC^{0,95 \text{ asymp }}_{\underline{X}_{n}}(\lambda) = \left[0,543 - Z_{1 - \frac{0,05}{2}} \times \sqrt{\frac{0,543}{35}} <  \lambda \right] \]
\[(1) \space \Leftrightarrow IC^{0,95 \text{ asymp }}_{\underline{X}_{n}}(\lambda) = \left[0,543 - 1,96 \times \sqrt{\frac{0,543}{35}} <  \lambda \right] \]
\[(1) \space \Leftrightarrow IC^{0,95 \text{ asymp }}_{\underline{X}_{n}}(\lambda) = \left[0,298 <  \lambda \right] \]

### 1. Calcul d'un interval de confiance asymptotique unilatéral droit de niveau 95% pour $\lambda$ ($IC_d$)

On obtient un  tel que : 

\[IC^{1+\alpha \text{ asymp }}_{\underline{X}_{n}}(\lambda) =  \left[\overline{X}_{n} + Z_{1 - \frac{\alpha}{2}} \times \sqrt{\frac{\overline{X}_{n}}{n}} >  \lambda \right] \space : (2)\]
\[(2) \space \Leftrightarrow IC^{0,95 \text{ asymp }}_{\underline{X}_{n}}(\lambda) = \left[0,543 + Z_{1 - \frac{0,05}{2}} \times \sqrt{\frac{0,543}{35}} >  \lambda \right] \]
\[(2) \space \Leftrightarrow IC^{0,95 \text{ asymp }}_{\underline{X}_{n}}(\lambda) = \left[0,543 + 1,96 \times \sqrt{\frac{0,543}{35}} >  \lambda \right] \]
\[(2) \space \Leftrightarrow IC^{0,95 \text{ asymp }}_{\underline{X}_{n}}(\lambda) = \left[0,787 >  \lambda \right] \]

## Peut-on accepter l’hypothèse que $\lambda = 1$ ? 

### Test d'hypothèses

On pose $H_0 : \lambda = 1$ et $ H_1 : \lambda \ne 1$.

### Observations

On a $\lambda \notin  IC_g$ et $\lambda \notin  IC_d$, autrement dit $\lambda \notin \left[0.298;0.787 \right]$ .

### Décision 

On ne peut donc accepter $H_0$.

### Conclusion 

Par conséquent, on a $\lambda \ne 1$.

### Commentaires

On peut vérifer cette négation, avec l'estimateur $W^{-\alpha}_{\underline{X}_{n}}(\lambda)$ de la manière suivante  : 

\[W^{\alpha}_{\underline{X}_{n}}(\lambda) = \left[ \frac{\underline{X}_{n}}{\overline{X}_{n}} < a_{\alpha} \right]  \space \text{ ou } \space  W^{\alpha}_{\underline{X}_{n}}(\lambda) = \left[ \overline{X}_{n} > b_{\alpha} \right]\]
\[P_{\lambda=1} (W^{-\alpha}_{\underline{X}_{n}}(\lambda)) \le \alpha \space \text{ et } \space P_{\lambda \ne 1} (W^{\alpha}_{\underline{X}_{n}}(\lambda)) \ge \alpha\]

\newpage

# Exercice 2

```{r 2_cleaning, echo=FALSE, results='hide'}
rm(list = ls(all = TRUE))
data.frame(unlist("all"))
```

## Contexte

Soit $X$, une variable aléatoire discrète représentant le nombre de pièces défectueuses par échantillon (représentée par une commande ou un lot). Les pièces peuvent être soient défectueuses, soient fonctionnelles. Notre échantillonage est donc extrait d'une épreuve de Bernouilli. La taille de l'échantillon est grande : $n > 100 \text{ avec } n = 140$.

On souhaite savoir si le client acceptera cet echantillon, et pour cela il faut qu'il contienne au moins 120 composants fonctionnels.

## Description du modèle de données

Notre échantillonnage aléatoire est simple tel que : $X_{n} = (X_{i})_{1 \le i \le n}$ avec le modèle suivant : $({0,1}(B(1,p)_{p})_{p \in [0,1]})$ sachant $p = 10\% = 0,1$.

On va comparer ce paramètre avec une estimation ponctuelle, afin de savoir si l'affirmation du fabricant est vraie. Pour cela nous allons réaliser deux tests : le premier du point de vue du fabricant ($TH_1$), le second du point de vue du client ($TH_2$).

## Observation ponctuelle

Dans notre observation ponctuelle (lot), on a observé que la proportion de pièces défectueuses est de `r 12/40` (`= 12/40`).

## Point de vue du fabricant ($TH_1$)

### Test d'hypothèses

\[H_0 : p_0 \le 0,1 \text{ contre } H_1 : p_0 > 0,1\]

\[W^{\alpha \text{ asymp }}_{X_n}(p) = \left\{ \frac{\underline{X}_{n}}{\overline{X}_{n}} > p + \frac{Z_{1-\alpha}}{\sqrt{n}} \times \sqrt{p(1-p)} \right\} \space : (3)\]
\[(3) \space \Leftrightarrow W^{0,05 \text{ asymp }}_{140}(p) = \left\{ \frac{\underline{X}_{n}}{\overline{X}_{n}} > 0,1 + \frac{1,96}{\sqrt{140}} \times \sqrt{0,1(1-0,1)} \right\} \]
\[(3) \space \Leftrightarrow W^{0,05 \text{ asymp }}_{140}(p) = \left\{ \frac{\underline{X}_{n}}{\overline{X}_{n}} > 0,1496 \right\} \]

### Observations

\[\frac{\underline{X}_{n}}{\overline{X}_{n}} = 0,0857 \notin W^{\alpha \text{ asymp }}_{X_n}(p)\]

### Décision

On accepte donc $H_0$ de $TH_1$.

### Conlcusion

Jusqu'à preuve du contraire, le client acceptera le lot.

## Point de vue du client ($TH_2$)

### Test d'hypothèses

\[H_0 : p_0 \ge 0,1 \text{ contre } H_1 : p_0 < 0,1\]

\[W^{\alpha \text{ asymp }}_{X_n}(p) = \left\{ \frac{\underline{X}_{n}}{\overline{X}_{n}} > p - \frac{Z_{1-\alpha}}{\sqrt{n}} \times \sqrt{p(1-p)} \right\} \space : (3)\]
\[(3) \space \Leftrightarrow W^{0,05 \text{ asymp }}_{140}(p) = \left\{ \frac{\underline{X}_{n}}{\overline{X}_{n}} > 0,1 - \frac{1,96}{\sqrt{140}} \times \sqrt{0,1(1-0,1)} \right\} \]
\[(3) \space \Leftrightarrow W^{0,05 \text{ asymp }}_{140}(p) = \left\{ \frac{\underline{X}_{n}}{\overline{X}_{n}} > 0,0503 \right\} \]

### Observations

\[\frac{\underline{X}_{n}}{\overline{X}_{n}} = 0,0857 \notin W^{\alpha \text{ asymp }}_{X_n}(p)\]

### Décision

On accepte donc $H_0$ $TH_2$.

### Conlcusion

Jusqu'à preuve du contraire, le client n'acceptera pas le lot.

## Commentaires

L'acceptation du lot a été évaluée depuis les points de vues des deux parties.

**On se place du point de vue du client, il ne faudrait donc pas tester $TH_2$ mais seulement $TH_1$. En effet, en se placant du côté du client, on souhaite seulement évaluer ce que craint le client de rejeter à tord.**

\newpage

# Exercice 3

```{r 3_cleaning, echo=FALSE, results='hide'}
rm(list = ls(all = TRUE))
data.frame(unlist("all"))
```

## Contexte

Nous introduisons les variables $x$, $A$, $S$, $E$, $Y$, $\theta$, et $Z$ comme suit : 
Une expérience chimique consiste à ajouter une dose $x$ d'un agent $A$ dans une solution $S$. Après réaction, on mesure la quantité d'une espèce $E$. Pour $x$ donné, on suppose qu'il est pertinent de représenter cette mesure par une variable aléatoire $Y = \theta x^2 + aZ$, $a$ connu, $\theta$ un paramètre réel inconnu et $Z$ une variable aléatoire normale centrée réduite.

## Estimation du paramètre $\theta$

Pour estimer le paramètre $\theta$, on fait $n(n \ge 1)$ essais indépendants avec des doses de l’agent $A$ notées $X_1, \ldots X_n$. De $Y$, on extrait donc un échantillon aléatoire bernoullien $Y_n = (Y_1 \ldots Y_n)$.

### Modèle statistique associé à $Y_n$

### Calcul

On pose le modèle statistique suivant à deux paramètres : 
\[( \mathbb{R}^n,  \otimes_{i=1}^{n} N(\theta x^2, a^2)_{(\theta, a) \in \mathbb{R}^{2} \times ]0;+\infty[})\]

Avec pour vraissemblance : 
\[L(Y_{\underline{X}_n}, \theta, a^2) = (2 \pi a^2)^{\frac{-n}{2}} \times e^{\frac{\sum_{i = 1}^{n} (Y_i - \theta_{i}^{2})^2}{2a^2}}\]

Et avec pour comme régularité : 
\[ log L(Y_{\underline{X}_n}, \theta, a^2) ) = log(2\pi)^{\frac{-n}{2}} - \frac{n}{2} \ln x - \frac{\sum_{i=1}^{n} (Y_i - \theta_{i}^{2})^2}{2a^2}  = g(\theta, a^2)\]

### Calcul de la borne de Cramer-Rao pour $\theta$

### Calcul de $\hat{\theta}_n$

### Démonstration de $\hat{\theta}_n$ en tant qu'estimateur efficace de $\theta$

### Identification de la loi de $\hat{\theta}_n$

### Calcul d'un intervalle de confiance ($IC$) de niveau $1-\alpha$ pour $\theta$

## Estimation ponctuelle du paramètre $\theta$

### Description des données

```{r 3_data_import, echo=FALSE, results='hide'}
# On importe les données avec les commandes suivantes
d3 <- read_delim("../data/donnees.exo3.csv", 
    delim = ";", escape_double = FALSE, locale = locale(decimal_mark = ","), 
    trim_ws = TRUE, show_col_types = FALSE)
d3 <- select(d3, x, y)
```

L'effectif des données est de `r dim(d3)[1]`.

La table suivante résume la dispersion de nos données :

```{r 3_data_description, echo=FALSE}
summary(d3)
```

```{r 3_correlation, echo=FALSE, results='hide'}
d3 <- dplyr::mutate(d3, x2 = d3$x * d3$x)
# regression line (y~x)
Dr<-lm(formula = d3$y~d3$x2)
a_coeff <- round(Dr$coefficients[2], digits = 2)
b_coeff <- round(Dr$coefficients[1], digits = 2)
model<-paste0("Y = ", a_coeff,"x² + ", b_coeff)
```

Le graphique, ci-dessous illustre le modèle aléatoire suivant $Y = \theta x^2 + aZ$  soulignant la relation linéaire entre $Y$ et $x^2$, tel que $Y = aX + b$ avec $a=$ `r a_coeff` et $b=$ `r b_coeff`.

```{r 3_graph, echo=FALSE, fig.asp = .63}
# http://www.sthda.com/english/wiki/correlation-test-between-two-variables-in-r#visualize-your-data-using-scatter-plots
library("ggpubr")
ggscatter(d3, x = "x2", y = "y", 
          add = "reg.line", conf.int = TRUE, 
          cor.coef = TRUE, cor.method = "pearson",
          title = model,
          xlab = "Agent A (x²)", ylab = "Espèce E (Y)")
```

### Calcul d'une estimation ponctuelle de $\theta$



### Calcul d'un intervalle de confiance ($IC$) de niveau 95%  pour $\theta$

### Evaluation de la significativité de l'augmentation de $\theta$

On souhaite savoir si l'on peut accepter au seuil de 5% l'hypothèse $H_0 : \theta > \theta_{passé} \Leftrightarrow H_0 : \theta > 0,9 $.
