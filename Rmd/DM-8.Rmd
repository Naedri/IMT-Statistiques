---
title: "UE Probabilité et Statistique - Mathématiques"
subtitle: "Devoir Maison n°8"
author: "Vincent Escoffier, Adrien Jallais, Théo Martel, Louis Muzellec."
place: "IMT-Atlantique - FIL A2"
date: "`r format(Sys.time(), '%d %B %Y')`"
knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding, output_dir = "../output") })
output:
  pdf_document: 
    latex_engine: xelatex  # More modern PDF typesetting engine
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE, tidy.opts = list(width.cutoff = 79),
  tidy = TRUE, fig.width = 6, fig.height = 6,
  warning = FALSE, message = FALSE
)
```

## Préparation de l'environnement

R et Rstudio seront utilisés pour la rédaction de ce DM en Rmarkdown, ainsi que les packages suivants :

```{r packages_loading, results='hide'}
library(readr)
library(dplyr)
library(ggplot2)
library(knitr)
library(ggpubr)
```

\newpage

# Exercice 1

```{r 1_cleaning, echo=FALSE, results='hide'}
rm(list = ls(all = TRUE))
data.frame(unlist("all"))
```

## Contexte

Soit $X$, la variable aléatoire représentant le nombre d'accidents par assuré. $X$ est une variables aléatoire discrète et il est admis que l'occurence des sinistres $X$ suit une loi de Poisson pour laquelle on recherche le paramètre inconnu $\lambda >0$ (notée $\mathscr{P_{\lambda}}$). 
<!--Et pour $\lambda > 20$, on a $E_\lambda(X) = \lambda = V_\lambda (X)$.-->

Pour cela, on a disposition un échantillon aléatoire bernouillien $\underline{X}_{n} = (X_1, \ldots, X_n) \text{, } n \ge 1$. Le modèle d'échantillonage associé est le suivant : $(\mathbb{N}, (\mathscr{P}_{\lambda})_{\lambda>0})^{n}$. 

La statistique de test associée à cet échantillon est $n \overline{X}_n$, qui représente le nombre total d'observations.

### Description des données

```{r 1_data_import, echo=FALSE, results='hide'}
d1 <- read_delim("../data/donnees.exo1.csv", 
    delim = ";", escape_double = FALSE, trim_ws = TRUE, show_col_types = FALSE)
overlineXn <- mean(d1$sinistre)
n <- length(d1$sinistre)
```

L'histogramme suivant résument la dispersion de nos données :

```{r 1_data_description, echo=FALSE, fig.asp = .63}
p <- ggplot(d1, aes(x=sinistre), fill=factor(id)) + geom_bar(fill="lightblue") + theme_classic()
p + ggtitle("Histogramme des sinistres") + xlab("Nombre de sinistre(s) par individus.") + ylab("Effectif dans l'échantillon")
```

L'effectif de l'échantillon est de `r dim(d1)[1]`.
A partir de $\overline{X}_{n} = \frac{\sum_{i=0}^n x_i}{n} =$ `r round(x=overlineXn, digits=2)`, on a $n \overline{X}_{n} =$ `r n*overlineXn`.

## Intervalle de confiance ($IC$) unilatéral pour $\lambda$

Pour rechercher une estimation de $\lambda$, on peut utiliser, à distance finie, la fonction pivotale $n \overline{X}_n$ qui suit une loi de Poisson de paramètre $n \lambda$ : $n \overline{X}_n \leadsto \mathscr{P}_{n\lambda}$.

Notre modèle étant discret, avec le livret du module 2 du cours (page 45), on peut déduire l'intervalle de confiance par excès du paramètre $\lambda$ :

\[IC^{1-\alpha+}_{\underline{X}_{n}}(\lambda) = \left[ \frac{\chi^2_{2n \overline{X}_n} (\alpha_2)}{2n} ; \frac{\chi^2_{2 (n \overline{X}_n + 1)} (1 - \alpha_1)}{2n} \right]  \text{ avec } \alpha = \alpha_1 + \alpha_2 \space : (IC_1)\] 

Or la table statistique des fractiles de la loi du $\chi^2$ fournie, ne nous permet pas de connaître les fractiles d'un $\chi^2$ de degré de liberté supérieur à 30. En effet, on a $2n \overline{X}_n =$ `r 2*n*overlineXn` et $2 (n \overline{X}_n + 1) =$ `r 2*(n*overlineXn + 1)`.
Nous ne pouvons donc  utiliser l'$IC_1$. 

Ainsi on considèrera l'effectif de notre échantillon grand. Dès lors, on donne la fonction pivotale asymptotique suivante :
\[\frac{\sqrt{n}(\overline{X}_n - \lambda)}{\sqrt{\overline{X}_n}} \xrightarrow{\mathit{CL}} \mathscr{N}(0,1)\]

On en déduit donc un intervalle de confiance par excès ($IC_2$) asymptotique, en utilisant les fractiles de loi normale :
\[IC^{1-\alpha \text{, asymp}}_{\underline{X}_{n}}(\lambda) =  \left[\overline{X}_{n} - Z_{1 - \frac{\alpha}{2}} \times \sqrt{\frac{\overline{X}_{n}}{n}} \space ; \space  
\overline{X}_{n} + Z_{1 - \frac{\alpha}{2}} \times \sqrt{\frac{\overline{X}_{n}}{n}}
\space \right] \space : (IC_2)\]

Dans la suite de cet exercice, nous utiliserons l'$IC_2$ pour l'estimation du paramètre $\lambda$.

### 1. Calcul d'un interval de confiance asymptotique unilatéral gauche de niveau 95% pour $\lambda$ ($IC_g$)

On obtient un $IC_g$ tel que : 

\[IC^{1-\alpha \text{, asymp}}_{\underline{X}_{n}}(\lambda) =  \left[\overline{X}_{n} - Z_{1 - \frac{\alpha}{2}} \times \sqrt{\frac{\overline{X}_{n}}{n}} <  \lambda \right] \space : (1)\]
\[(1) \space \Leftrightarrow IC^{0,95 \text{, asymp}}_{\underline{X}_{n}}(\lambda) = \left[0,543 - Z_{1 - \frac{0,05}{2}} \times \sqrt{\frac{0,543}{35}} <  \lambda \right] \]
\[(1) \space \Leftrightarrow IC^{0,95 \text{, asymp}}_{\underline{X}_{n}}(\lambda) = \left[0,543 - 1,96 \times \sqrt{\frac{0,543}{35}} <  \lambda \right] \]
\[(1) \space \Leftrightarrow IC^{0,95 \text{, asymp}}_{\underline{X}_{n}}(\lambda) = \left[0,298 <  \lambda \right] \]

### 2. Calcul d'un interval de confiance asymptotique unilatéral droit de niveau 95% pour $\lambda$ ($IC_d$)

On obtient un $IC_d$ tel que : 

\[IC^{1+\alpha \text{, asymp}}_{\underline{X}_{n}}(\lambda) =  \left[\overline{X}_{n} + Z_{1 - \frac{\alpha}{2}} \times \sqrt{\frac{\overline{X}_{n}}{n}} >  \lambda \right] \space : (2)\]
\[(2) \space \Leftrightarrow IC^{0,95 \text{, asymp}}_{\underline{X}_{n}}(\lambda) = \left[0,543 + Z_{1 - \frac{0,05}{2}} \times \sqrt{\frac{0,543}{35}} >  \lambda \right] \]
\[(2) \space \Leftrightarrow IC^{0,95 \text{, asymp}}_{\underline{X}_{n}}(\lambda) = \left[0,543 + 1,96 \times \sqrt{\frac{0,543}{35}} >  \lambda \right] \]
\[(2) \space \Leftrightarrow IC^{0,95 \text{, asymp}}_{\underline{X}_{n}}(\lambda) = \left[0,787 >  \lambda \right] \]

### Commentaires

L'utilisation d'intervalles de confiance unilatéraux est inadapté pour les lois symétriques comme la loi normale, si nous en avions eu la possibilité, il aurait fallu utiliser l'$IC_1$.

## Peut-on accepter l’hypothèse que $\lambda = 1$ ? 

Nous répondrons à cette question, en évaluant un test d'hypothèse.

### Test d'hypothèses

On pose $H_0 : \lambda = 1$ contre $H_1 : \lambda \ne 1$.

### Observations

On observe que selon $H_0$, on a $\lambda \notin  IC_g$ et $\lambda \notin  IC_d$. Autrement dit $\lambda \notin \left[ 0.298;0.787 \right]$

### Décision 

On rejette $H_0$, jusqu'à preuve du contraire.

### Conclusion 

Par conséquent, on ne peut accepter l'hypothèse $\lambda = 1$, et donc on a $\lambda \ne 1$.

### Commentaires

On peut vérifer cette négation, avec l'estimateur $W^{-\alpha}_{\underline{X}_{n}}(\lambda)$ de la manière suivante  : 

\[W^{\alpha}_{\underline{X}_{n}}(\lambda) = \left[ \frac{\underline{X}_{n}}{\overline{X}_{n}} < a_{\alpha} \right]  \space \text{ ou } \space  W^{\alpha}_{\underline{X}_{n}}(\lambda) = \left[ \overline{X}_{n} > b_{\alpha} \right]\]
\[P_{\lambda=1} (W^{-\alpha}_{\underline{X}_{n}}(\lambda)) \le \alpha \space \text{ et } \space P_{\lambda \ne 1} (W^{\alpha}_{\underline{X}_{n}}(\lambda)) \ge \alpha\]

\newpage

# Exercice 2

## Contexte

Soit $X$, une variable aléatoire discrète représentant le nombre de pièces défectueuses par échantillon (représentée par une commande ou un lot). Les pièces peuvent être soient défectueuses, soient fonctionnelles. Notre échantillonage est donc extrait d'une épreuve de Bernouilli. La taille de l'échantillon est grande : $n > 100 \text{ avec } n = 140$.

On souhaite savoir si le client acceptera cet echantillon, et pour cela il faut qu'il contienne au moins 120 composants fonctionnels.

### Description du modèle de données

Notre échantillonnage aléatoire est simple tel que : $X_{n} = (X_{i})_{1 \le i \le n}$ avec le modèle suivant : $({0,1}( \mathscr{B}(1,p)_{p})_{p \in [0,1]})$ sachant $p = 10\% = 0,1$.

On va comparer ce paramètre avec une estimation ponctuelle, afin de savoir si l'affirmation du fabricant est vraie. Pour cela nous allons réaliser deux tests : le premier du point de vue du fabricant ($TH_1$), le second du point de vue du client ($TH_2$).

### Observation ponctuelle

Dans notre observation ponctuelle (lot), on a observé que la proportion de pièces défectueuses est de `r round(12/140, digits=4)` ($= 12/140$).

## Point de vue du fabricant ($TH_1$)

### Test d'hypothèses
Le fabricant craint par dessus tout le rejet à tort de sa production, $p_0 \le 0,1$.

Son test est donc :

\[H_0 : p_0 \le 0,1 \text{ contre } H_1 : p_0 > 0,1\]

\[W^{\alpha \text{, asymp}}_{X_n}(p) = \left\{ \frac{\underline{X}_{n}}{\overline{X}_{n}} > p + \frac{Z_{1-\alpha}}{\sqrt{n}} \times \sqrt{p(1-p)} \right\} \space : (3)\]
\[(3) \space \Leftrightarrow W^{0,05 \text{, asymp}}_{140}(p) = \left\{ \frac{\underline{X}_{n}}{\overline{X}_{n}} > 0,1 + \frac{1,96}{\sqrt{140}} \times \sqrt{0,1(1-0,1)} \right\} \]
\[(3) \space \Leftrightarrow W^{0,05 \text{, asymp}}_{140}(p) = \left\{ \frac{\underline{X}_{n}}{\overline{X}_{n}} > 0,1496 \right\} \]

### Conclusion

\[\frac{\underline{X}_{n}}{\overline{X}_{n}} = 0,0857 \notin W^{\alpha \text{, asymp}}_{X_n}(p)\]

### Décision

Pour le $TH_1$, on ne rejette pas l'hypothèse $H_0$ jusqu'à preuve du contraire.

Donc jusqu'à preuve du contraire, la garantie du fabricant est vraie.

## Point de vue du client ($TH_2$)

### Test d'hypothèses

Le client va appliquer le principe de précaution, il craint de rejeter à tort $p_0 \ge 0,1$.

Son test est donc :

\[H_0 : p_0 \ge 0,1 \text{ contre } H_1 : p_0 < 0,1\]

\[W^{\alpha \text{, asymp}}_{X_n}(p) = \left\{ \frac{\underline{X}_{n}}{\overline{X}_{n}} > p - \frac{Z_{1-\alpha}}{\sqrt{n}} \times \sqrt{p(1-p)} \right\} \space : (3)\]
\[(3) \space \Leftrightarrow W^{0,05 \text{, asymp}}_{140}(p) = \left\{ \frac{\underline{X}_{n}}{\overline{X}_{n}} > 0,1 - \frac{1,96}{\sqrt{140}} \times \sqrt{0,1(1-0,1)} \right\} \]
\[(3) \space \Leftrightarrow W^{0,05 \text{, asymp}}_{140}(p) = \left\{ \frac{\underline{X}_{n}}{\overline{X}_{n}} > 0,0503 \right\} \]

### Conclusion

\[\frac{\underline{X}_{n}}{\overline{X}_{n}} = 0,0857 \notin W^{\alpha \text{, asymp}}_{X_n}(p)\]

### Décision

Pour le $TH_2$, on ne rejette pas l'hypothèse $H_0$ jusqu'à preuve du contraire.

Donc le principe de précaution du point de vue du client, conclue jusqu'à preuve du contraire, que la garantie du fabricant est fausse.

## Réponse

Les deux points de vue n'aboutissent pas à la même conclusion. Il faudrait augmenter la taille de l'échantillon et revoir l'hypothèse du modèle.

Cependant étant du point de vue du client, il est nécessire d'appliquer le principe de précaution et donc de privilégier le test d'hypothèse 2, $TH_2$, pour répondre à la question du devoir: "Le client acceptera ou refusera-t-il le lot ?".

Donc d'après $TH_2$, non le client n'acceptera pas le lot.

\newpage

# Exercice 3

```{r 3_cleaning, echo=FALSE, results='hide'}
rm(list = ls(all = TRUE))
data.frame(unlist("all"))
```

## Contexte

Une expérience chimique consiste à ajouter une dose $x$ d'un agent $A$ dans une solution $S$. Après réaction, on mesure la quantité d'une espèce $E$. 

Pour $x$ donné, on suppose qu'il est pertinent de représenter cette mesure par une variable aléatoire $Y = \theta x^2 + aZ$, $a$ ($a>0$) connu, $\theta$ ($\theta \in \mathbb{R}$) inconnu,  $Z$ une variable aléatoire ($Z \leadsto \mathscr{N}(0,1)$).

## Estimation du paramètre $\theta$

Pour estimer le paramètre $\theta$, on fait $n$ ($n \ge 1$) essais indépendants avec des doses de l’agent $A$ notées $x_1, \ldots, x_n$. De $Y$, on extrairt donc un échantillon aléatoire bernoullien : ${Y}_{\underline{X}_n} = (Y_{x_1}, \ldots, Y_{x_n})$.

### Modèle statistique associé à $\underline{Y}_n$

On se place dans un modèle statistique paramétré : 
\[( \mathbb{R}^n, \otimes_{i=1}^{n} \mathscr{N}(\theta x_{i}^{2}, a^2)_{(\theta, a) \in \mathbb{R}^{2} \times ]0;+\infty[})\]

La vraisemblance du modèle est : 
\[L(Y_{\underline{X}_n}, a^2,\theta) = (2 \pi a^2)^{-\frac{n}{2}} \times e^{\frac{\sum_{i=1}^{n} (Y_i - \theta x_{i}^{2})^2}{2a^2}}\]

### Régularité du modèle associé à $\underline{Y}_n$

La démonstration du livret du module 2 du cours (page 98), démontre la régularité du modèle suivant : 
\[( \mathbb{R}^n, \otimes_{i=1}^{n} \mathscr{N}(\theta_0 + \theta_1 x'_{i}, \sigma^2)_{(\theta_0, \theta_1, \sigma) \in \mathbb{R}^{2} \times ]0;+\infty[})\]

En posant $\theta_0 = 0$, $\theta_1 = \theta$ , $\sigma = a$ et $x'_{i} = x_{i}^{2}$, on retrouve le même modèle statistique associé plus haut à $\underline{Y}_n$. Ainsi le modèle de $\underline{Y}_n$ est régulier.

### Calcul de l'EMV $\hat{\theta}_n$

Selon le théorème de Gauss-Markov, on a :

\[\hat{\theta}_n = \frac{\sum_{i=1}^{n} ( x_i^2 - \overline{{x_n}^2} ) (Y_{x_i} - \overline{Y}_{\underline{X}_n})}{n S_{\underline{X}_n}^2}\]

avec :

\[\overline{{x_n}^2} = \frac{\sum_{i=1}^{n} x_i^2}{n}\]
et
\[S_{\underline{X}_n}^2 = \frac{\sum_{i=1}^{n} ( x_i^2 - \overline{{x_n}^2} )^2}{n}\]

### Démonstration de $\hat{\theta}_n$ en tant qu'estimateur efficace de $\theta$

Le modèle statistique étant régulier et les distributions d'échantillonnage normales, nous savons (selon le chapitre 2 du livret du module 2 du cours) que les EMV fournissent des estimateurs consistants efficaces ou asymptotiquement efficaces. <!--extrait p89 du ivret du module 2 du cours-->

Ainsi l'EMV $\hat{\theta}_n$ est un estimateur efficace de $\theta$.

### Calcul de la borne de Cramer-Rao pour $\theta$

La borne Cramér-Rao exprime une borne inférieure sur la variance d'un estimateur sans biais, basée sur l'information de Fisher ($\mathscr{I}$) (selon [stats.stackexchange.com](https://stats.stackexchange.com/questions/461035/cram%c3%a9r-rao-lower-bound-with-an-uncertain-observable)).

Or on sait que ce modèle statistique est régulier, et que le livret du module 2 du cours (page 89) définit $\hat{\theta}_n$ en tant qu'estimateur efficace de $\theta$, tel que :
\[\hat{\theta}_n \leadsto \mathscr{N}(\theta, \frac{a^2}{nS^2_{\underline{X}_n}})\]

Ainsi, on peut écrire la borne Cramér-Rao pour $\theta$ telle que : 
\[\mathscr{I}_{\underline{X}_n}(\theta)^{-1} = \frac{a^2}{nS^2_{\underline{X}_n}}\]

### Identification de la loi de $\hat{\theta}_n$

On a $\hat{\theta}_n$ tel que : 
\[\hat{\theta}_n \leadsto \mathscr{N}(\theta_1, \frac{a^2}{ nS^2_{\underline{X}_n} })\]

### Calcul d'un intervalle de confiance ($IC$) de niveau $1-\alpha$ pour $\theta$

Le livret du module 2 du cours (page 90), définit l'intervalle de confiance ($IC$) du paramètre $\theta$ tel que : 

\[IC^{1-\alpha}_{Y_{\underline{X}_{n}}}(\theta) =  \left[ \hat{\theta}_n - Z_{1- \frac{\alpha}{2}} \sqrt{\frac{a^2}{nS^2_{\underline{X}_n}}} ; \hat{\theta}_n + Z_{1- \frac{\alpha}{2}} \sqrt{\frac{a^2}{nS^2_{\underline{X}_n}}}  \right]\]

## Estimation ponctuelle du paramètre $\theta$

On pose suppose $a = 0.5$. 

### Description des données

```{r 3_data_import, echo=FALSE, results='hide'}
# On importe les données avec les commandes suivantes
d3 <- read_delim("../data/donnees.exo3.csv", 
    delim = ";", escape_double = FALSE, locale = locale(decimal_mark = ","), 
    trim_ws = TRUE, show_col_types = FALSE)
d3 <- select(d3, x, y)
```

```{r 3_correlation, echo=FALSE, results='hide'}
d3 <- dplyr::mutate(d3, x2 = d3$x * d3$x)
d3 <- dplyr::select(d3, x, x2, y)
# regression line (y~x)
lm<-lm(formula = d3$y~d3$x2)
a_coeff <- round(lm$coefficients[2], digits = 2)
b_coeff <- round(lm$coefficients[1], digits = 2)
model<-paste0("Y = ", a_coeff,"x² + ", b_coeff)
# ggscatter parameters
conf.int.level <- 0.95
cor.method <- "pearson"
```

L'effectif des données est de `r dim(d3)[1]`.

Dans la table suivante on présente les données nécessaires à l'étude du modèle de régression linéaire :

```{r 3_data_description, echo=FALSE}
# https://bookdown.org/yihui/rmarkdown-cookbook/kable.html
d3_temp <- d3
colnames(d3_temp) <- c("$x_{i}$", "$x_{i}^{2}$", "$y_{i}$")
kable(x=t(d3_temp), digits = 3)
```

Le graphique, ci-dessous illustre le modèle aléatoire suivant : $Y = \theta x^2 + aZ$,  soulignant la relation linéaire entre $Y$ et $x^2$, tel que $Y = ax² + b$ avec $a=$ `r a_coeff` et $b=$ `r b_coeff`, calculés avec la méthode de corrélation de `r cor.method` et avec un intervalle de confiance de `r conf.int.level`.

```{r 3_graph, echo=FALSE, fig.asp = .63}
# http://www.sthda.com/english/wiki/correlation-test-between-two-variables-in-r#visualize-your-data-using-scatter-plots
ggscatter(d3, x = "x2", y = "y", 
          add = "reg.line", conf.int = TRUE, 
          cor.coef = TRUE, cor.method = cor.method,
          conf.int.level =  conf.int.level,
          title = model,
          xlab = "Agent A (x²)", ylab = "Espèce E (Y)",
          color="blue")
```

Avec un R si grand, on peut supposer l'intensité de liaison entre $Y$ et $x^2$ très forte. En effet, on a : 

```{r 3_x2_coef, echo=FALSE}
lmsum <- as.data.frame(coef(summary(lm)))
rownames(lmsum) <- c("Ordonnée à l'origine","$x_{i}^{2}$")
kable(lmsum, digits = 3)
```

### Calcul d'une estimation ponctuelle de $\theta$

Il a pu être défini que : 

\[\hat{\theta}_n = \frac{\sum_{i=1}^{n} ( x_i^2 - \overline{{x_n}^2} ) (Y_{x_i} - \overline{Y}_{\underline{X}_n})}{n S_{\underline{X}_n}^2}\]

Ainsi à partir de l'échantillon, comme on a :

```{r 3_ns2Xn, echo=FALSE, results='hide'}

```
<!--TODO :  remplacer 501,653 ; 656,906 ; 0,7637 et 2,7 par les valeurs numériques calculées plus haut car elles nous serviront pour faire le tableau-->
\[nS_{\underline{X}_n}^2 = \sum_{i=1}^{n}(x^2 - \overline{x^2_n}) = 656,906\]
et
\[\sum_{i=1}^{n}(x^2 - \overline{x^2_n})(Y_{x_i} - \overline{Y_{\underline{X}_n}}) = 501,653\]

On peut en déduire $\hat{\theta}_{n}$, tel que : 
\[\hat{\theta}_{n} = \theta = 0,7637\]

On obtient dès lors la table suivante :

```{r 3_table_tilde, echo=FALSE}
# TODO : replace raw value theta_tilde
theta_tilde <- 0.7637
d3_temp <- d3
d3_temp <- dplyr::mutate(d3_temp, yTilde = theta_tilde * d3_temp$x2)
d3_temp <- dplyr::mutate(d3_temp, eTilde = d3_temp$y - d3_temp$yTilde)
colnames(d3_temp) <- c("$x_{i}$", "$x_{i}^{2}$", "$y_{i}$", "$\\tilde{y_i} = \\tilde{\\theta}x^2$", "$\\tilde{e_i} = y_i - \\tilde{y_i}$")
kable(x=t(d3_temp), digits = 2) # if digits = 3 -> output is bad
```

On pourra noter que l'on obtient un écart résiduel non nul, tel que :

\[\sum_{i=1}^{n} \tilde{e_i} = 2,7\]

### Calcul d'un intervalle de confiance ($IC$) de niveau 95%  pour $\theta$

\[ \left[ \theta - Z_{1- \frac{\alpha}{2}} \sqrt{\frac{a^2}{nS^2_{\underline{X}_n}}} ;  \theta + Z_{1- \frac{\alpha}{2}} \sqrt{\frac{a^2}{nS^2_{\underline{X}_n}}} \right]  \space : (3)\]

Or on suppose que l'écart-type ($a$) est tel que $a = 0.5$, ainsi :

\[(3) \space \Leftrightarrow \left[ 0,7637 - 1,96 \times \sqrt{\frac{0,5^2}{656,906}} ; 0,7637 + 1,96 \times \sqrt{\frac{0,5^2}{656,906}}
 \right]\]

\[(3) \space \Leftrightarrow \left[ 0,7254 ; 0,8019 \right]\]

### Evaluation d'une évolution significative de $\theta$

On ne souhaite ici évaluer une croissance ou une décroissance, de $\theta$ ; mais seulement savoir s'il y a une différence.

Ainsi, on souhaite savoir si l'on peut accepter au seuil de 5% l'hypothèse $H_1 : \theta = \theta_{passé} \Leftrightarrow H_0 : \theta = 0,9$ contre $H_1 : \theta \ne 0,9$.

#### Test d'hypothèses

\[W^\alpha_{Y_{\underline{X}_n}}(\theta) = \left\{ \mid \hat{\theta}_n - 0,9 \mid > Z_{1- \frac{\alpha}{2}} \sqrt{\frac{a^2}{nS^2_{\underline{X}_n}}} \right\} \space : (4)\]

\[(4) \space \Leftrightarrow W^\alpha_{Y_{\underline{X}_n}}(\theta) = \left\{ \mid \hat{\theta}_n - 0,9 \mid > 1,96 \times \sqrt{\frac{0,5^2}{656,906}} \right\}\]

\[(4) \space \Leftrightarrow W^\alpha_{Y_{\underline{X}_n}}(\theta) = \left\{ \mid \hat{\theta}_n - 0,9 \mid > 0,038 \right\}\]

#### Observations

On observe :

\[\mid \hat{\theta}_n - 0,9 \mid = \mid 0,7637 - 0,9 \mid = \mid -0.1363 \mid = 0.1363 \space : (5)\]
\[(5) \space \Leftrightarrow \mid \hat{\theta}_n - 0,9 \mid \in W^\alpha_{Y_{\underline{X}_n}}\]

#### Décision

Au seuil de de 5%, on rejete $H_0$ jusqu'à preuve du contraire.

#### Conlcusion

On en conclue que la valeur du paramètre $\theta$ a évolu significativement par rapport aux mesures précédentes.
