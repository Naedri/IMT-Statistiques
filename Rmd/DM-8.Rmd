---
title: "UE Probabilité et Statistique - Mathématiques"
subtitle: "Devoir Maison n°8"
author: "Vincent Escoffier, Adrien Jallais, Théo Martel, Louis Muzellec."
place: "IMT-Atlantique - FIL A2"
date: "`r format(Sys.time(), '%d %B %Y')`"
knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding, output_dir = "../output") })
output:
  pdf_document: 
    latex_engine: xelatex  # More modern PDF typesetting engine
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE, tidy.opts = list(width.cutoff = 79),
  tidy = TRUE, fig.width = 6, fig.height = 6,
  warning = FALSE, message = FALSE
)
```

## Préparation de l'environnement

R et Rstudio seront utilisés pour la rédaction de ce DM, ainsi que les packages suivants :

```{r packages_loading, results='hide'}
library(readr)
library(dplyr)
library(ggplot2)
library(knitr)
```

\newpage

# Exercice 1

```{r 1_cleaning, echo=FALSE, results='hide'}
rm(list = ls(all = TRUE))
data.frame(unlist("all"))
```

## Contexte

Soit $X$, la variable aléatoire représentant le nombre d'accidents par assuré. $X$ est une variables aléatoire discrète et il est admis que l'occurence des sinistres $X$ suit une loi de Poisson pour laquelle on recherche le paramètre inconnu $\lambda >0$ (notée $\mathscr{P_{\lambda}}$). 
<!--Et pour $\lambda > 20$, on a $E_\lambda(X) = \lambda = V_\lambda (X)$.-->

Pour cela, on a disposition un échantillon aléatoire bernouillien $\underline{X}_{n} = (X_1 \ldots X_n) \text{, } n \ge 1$. Le modèle d'échantillonage associé est le suivant : $(\mathbb{N}, (\mathscr{P}_{\lambda})_{\lambda>0})^{n}$. 

La statistique de test associée à cet échantillon est $n \overline{X}_n$, qui représente le nombre total d'observations.

### Description des données

```{r 1_data_import, echo=FALSE, results='hide'}
d1 <- read_delim("../data/donnees.exo1.csv", 
    delim = ";", escape_double = FALSE, trim_ws = TRUE, show_col_types = FALSE)
overlineXn <- mean(d1$sinistre)
n <- length(d1$sinistre)
```

L'histogramme suivant résument la dispersion de nos données :

```{r 1_data_description, echo=FALSE, fig.asp = .63}
p <- ggplot(d1, aes(x=sinistre), fill=factor(id)) + geom_bar(fill="lightblue") + theme_classic()
p + ggtitle("Histogramme des sinistres") + xlab("Nombre de sinistre(s) par individus.") + ylab("Effectif dans l'échantillon")
```

L'effectif de l'échantillon est de `r dim(d1)[1]`.
A partir de $\overline{X}_{n} = \frac{\sum_{i=0}^n x_i}{n} =$ `r round(x=overlineXn, digits=2)`, on a $n \overline{X}_{n} =$ `r n*overlineXn`.

## Intervalle de confiance ($IC$) unilatéral pour $\lambda$

Pour rechercher une estimation de $\lambda$, on peut utiliser, à distance finie, la fonction pivotale $n \overline{X}_n$ qui suit une loi de Poisson de paramètre $n \lambda$ : $n \overline{X}_n \leadsto \mathscr{P}_{n\lambda}$.

Notre modèle étant discret, avec le livret du module 2 du cours (page 45), on peut déduire l'intervalle de confiance par excès du paramètre $\lambda$ :

\[IC^{1-\alpha+}_{\underline{X}_{n}}(\lambda) = \left[ \frac{\chi^2_{2n \overline{X}_n} (\alpha_2)}{2n} ; \frac{\chi^2_{2 (n \overline{X}_n + 1)} (1 - \alpha_1)}{2n} \right]  \text{ avec } \alpha = \alpha_1 + \alpha_2 \space : (IC_1)\] 

Or la table statistique des fractiles de la loi du $\chi^2$ fournie, ne nous permet pas de connaître les fractiles d'un $\chi^2$ de degré de liberté supérieur à 30. En effet, on a $2n \overline{X}_n =$ `r 2*n*overlineXn` et $2 (n \overline{X}_n + 1) =$ `r 2*(n*overlineXn + 1)`.
Nous ne pouvons donc  utiliser l'$IC_1$. 

Ainsi on considèrera l'effectif de notre échantillon grand. Dès lors, on donne la fonction pivotale asymptotique suivante :
\[\frac{\sqrt{n}(\overline{X}_n - \lambda)}{\sqrt{\overline{X}_n}} \xrightarrow{\mathit{CL}} N(0,1)\]

On en déduit donc un intervalle de confiance par excès ($IC_2$) asymptotique, en utilisant les fractiles de loi normale :
\[IC^{1-\alpha \text{, asymp}}_{\underline{X}_{n}}(\lambda) =  \left[\overline{X}_{n} - Z_{1 - \frac{\alpha}{2}} \times \sqrt{\frac{\overline{X}_{n}}{n}} \space ; \space  
\overline{X}_{n} + Z_{1 - \frac{\alpha}{2}} \times \sqrt{\frac{\overline{X}_{n}}{n}}
\space \right] \space : (IC_2)\]

Dans la suite de cet exercice, nous utiliserons l'$IC_2$ pour l'estimation du paramètre $\lambda$.

### 1. Calcul d'un interval de confiance asymptotique unilatéral gauche de niveau 95% pour $\lambda$ ($IC_g$)

On obtient un $IC_g$ tel que : 

\[IC^{1-\alpha \text{, asymp}}_{\underline{X}_{n}}(\lambda) =  \left[\overline{X}_{n} - Z_{1 - \frac{\alpha}{2}} \times \sqrt{\frac{\overline{X}_{n}}{n}} <  \lambda \right] \space : (1)\]
\[(1) \space \Leftrightarrow IC^{0,95 \text{, asymp}}_{\underline{X}_{n}}(\lambda) = \left[0,543 - Z_{1 - \frac{0,05}{2}} \times \sqrt{\frac{0,543}{35}} <  \lambda \right] \]
\[(1) \space \Leftrightarrow IC^{0,95 \text{, asymp}}_{\underline{X}_{n}}(\lambda) = \left[0,543 - 1,96 \times \sqrt{\frac{0,543}{35}} <  \lambda \right] \]
\[(1) \space \Leftrightarrow IC^{0,95 \text{, asymp}}_{\underline{X}_{n}}(\lambda) = \left[0,298 <  \lambda \right] \]

### 2. Calcul d'un interval de confiance asymptotique unilatéral droit de niveau 95% pour $\lambda$ ($IC_d$)

On obtient un $IC_d$ tel que : 

\[IC^{1+\alpha \text{, asymp}}_{\underline{X}_{n}}(\lambda) =  \left[\overline{X}_{n} + Z_{1 - \frac{\alpha}{2}} \times \sqrt{\frac{\overline{X}_{n}}{n}} >  \lambda \right] \space : (2)\]
\[(2) \space \Leftrightarrow IC^{0,95 \text{, asymp}}_{\underline{X}_{n}}(\lambda) = \left[0,543 + Z_{1 - \frac{0,05}{2}} \times \sqrt{\frac{0,543}{35}} >  \lambda \right] \]
\[(2) \space \Leftrightarrow IC^{0,95 \text{, asymp}}_{\underline{X}_{n}}(\lambda) = \left[0,543 + 1,96 \times \sqrt{\frac{0,543}{35}} >  \lambda \right] \]
\[(2) \space \Leftrightarrow IC^{0,95 \text{, asymp}}_{\underline{X}_{n}}(\lambda) = \left[0,787 >  \lambda \right] \]

### Commentaires

L'utilisation d'intervalles de confiance unilatéraux est inadapté pour les lois symétriques comme la loi normale, si nous en avions eu la possibilité, il aurait fallu utiliser l'$IC_1$.

## Peut-on accepter l’hypothèse que $\lambda = 1$ ? 

Nous répondrons à cette question, en évaluant un test d'hypothèse.

### Test d'hypothèses

On pose $H_0 : \lambda = 1$ contre $H_1 : \lambda \ne 1$.

### Observations

On observe que selon $H_0$, on a $\lambda \notin  IC_g$ et $\lambda \notin  IC_d$. Autrement dit $\lambda \notin \left[ 0.298;0.787 \right]$

### Décision 

On rejette $H_0$, jusqu'à preuve du contraire.

### Conclusion 

Par conséquent, on ne peut accepter l'hypothèse $\lambda = 1$, et donc on a $\lambda \ne 1$.

### Commentaires

On peut vérifer cette négation, avec l'estimateur $W^{-\alpha}_{\underline{X}_{n}}(\lambda)$ de la manière suivante  : 

\[W^{\alpha}_{\underline{X}_{n}}(\lambda) = \left[ \frac{\underline{X}_{n}}{\overline{X}_{n}} < a_{\alpha} \right]  \space \text{ ou } \space  W^{\alpha}_{\underline{X}_{n}}(\lambda) = \left[ \overline{X}_{n} > b_{\alpha} \right]\]
\[P_{\lambda=1} (W^{-\alpha}_{\underline{X}_{n}}(\lambda)) \le \alpha \space \text{ et } \space P_{\lambda \ne 1} (W^{\alpha}_{\underline{X}_{n}}(\lambda)) \ge \alpha\]

\newpage

# Exercice 2

```{r 2_cleaning, echo=FALSE, results='hide'}
rm(list = ls(all = TRUE))
data.frame(unlist("all"))
```

## Contexte

Soit $X$, une variable aléatoire discrète représentant le nombre de pièces défectueuses par échantillon (représentée par une commande ou un lot). Les pièces peuvent être soient défectueuses, soient fonctionnelles. Notre échantillonage est donc extrait d'une épreuve de Bernouilli. La taille de l'échantillon est grande : $n > 100 \text{ avec } n = 140$.

On souhaite savoir si le client acceptera cet echantillon, et pour cela il faut qu'il contienne au moins 120 composants fonctionnels.

## Description du modèle de données

Notre échantillonnage aléatoire est simple tel que : $X_{n} = (X_{i})_{1 \le i \le n}$ avec le modèle suivant : $({0,1}(B(1,p)_{p})_{p \in [0,1]})$ sachant $p = 10\% = 0,1$.

On va comparer ce paramètre avec une estimation ponctuelle, afin de savoir si l'affirmation du fabricant est vraie. Pour cela nous allons réaliser deux tests : le premier du point de vue du fabricant ($TH_1$), le second du point de vue du client ($TH_2$).

## Observation ponctuelle

Dans notre observation ponctuelle (lot), on a observé que la proportion de pièces défectueuses est de `r 12/140` (`= 12/140`).

## Point de vue du fabricant ($TH_1$)

### Test d'hypothèses

\[H_0 : p_0 \le 0,1 \text{ contre } H_1 : p_0 > 0,1\]

\[W^{\alpha \text{, asymp}}_{X_n}(p) = \left\{ \frac{\underline{X}_{n}}{\overline{X}_{n}} > p + \frac{Z_{1-\alpha}}{\sqrt{n}} \times \sqrt{p(1-p)} \right\} \space : (3)\]
\[(3) \space \Leftrightarrow W^{0,05 \text{, asymp}}_{140}(p) = \left\{ \frac{\underline{X}_{n}}{\overline{X}_{n}} > 0,1 + \frac{1,96}{\sqrt{140}} \times \sqrt{0,1(1-0,1)} \right\} \]
\[(3) \space \Leftrightarrow W^{0,05 \text{, asymp}}_{140}(p) = \left\{ \frac{\underline{X}_{n}}{\overline{X}_{n}} > 0,1496 \right\} \]

### Observations

\[\frac{\underline{X}_{n}}{\overline{X}_{n}} = 0,0857 \notin W^{\alpha \text{, asymp}}_{X_n}(p)\]

### Décision

Pour le $TH_1$, on ne rejette pas l'hypothèse $H_0$ jusqu'à preuve du contraire.

### Conlcusion

Jusqu'à preuve du contraire, le client acceptera le lot.

## Point de vue du client ($TH_2$)

### Test d'hypothèses

\[H_0 : p_0 \ge 0,1 \text{ contre } H_1 : p_0 < 0,1\]

\[W^{\alpha \text{, asymp}}_{X_n}(p) = \left\{ \frac{\underline{X}_{n}}{\overline{X}_{n}} > p - \frac{Z_{1-\alpha}}{\sqrt{n}} \times \sqrt{p(1-p)} \right\} \space : (3)\]
\[(3) \space \Leftrightarrow W^{0,05 \text{, asymp}}_{140}(p) = \left\{ \frac{\underline{X}_{n}}{\overline{X}_{n}} > 0,1 - \frac{1,96}{\sqrt{140}} \times \sqrt{0,1(1-0,1)} \right\} \]
\[(3) \space \Leftrightarrow W^{0,05 \text{, asymp}}_{140}(p) = \left\{ \frac{\underline{X}_{n}}{\overline{X}_{n}} > 0,0503 \right\} \]

### Observations

\[\frac{\underline{X}_{n}}{\overline{X}_{n}} = 0,0857 \notin W^{\alpha \text{, asymp}}_{X_n}(p)\]

### Décision

Pour le $TH_2$, on accepte donc $H_0$.

### Conlcusion

Jusqu'à preuve du contraire, le client n'acceptera pas le lot. **??Problème de formulation ou de conclusion -> à vérifier??**

## Commentaires

L'acceptation du lot a été évaluée depuis les points de vues des deux parties.

**On se place du point de vue du client, il ne faudrait donc pas tester $TH_2$ mais seulement $TH_1$. En effet, en se placant du côté du client, on souhaite seulement évaluer ce que craint le client de rejeter à tord.**
**On a réalisé deux tests, si ilssont contradictaatoires => prendre le test du point de vue client.**

**??? TODO : vérifier la formulation des deux tests, avec le livret de cours module 2 (page 62).????**

\newpage

# Exercice 3

**LA PROF VEUT QUASI LA MEME CHOSE QUE L'EXO FAIT EN COURS (feuille donnée au dernier cours sur la regression)**

```{r 3_cleaning, echo=FALSE, results='hide'}
rm(list = ls(all = TRUE))
data.frame(unlist("all"))
```

## Contexte

Nous introduisons les variables $x$, $A$, $S$, $E$, $Y$, $\theta$, et $Z$ comme suit : 
Une expérience chimique consiste à ajouter une dose $x$ d'un agent $A$ dans une solution $S$. Après réaction, on mesure la quantité d'une espèce $E$. Pour $x$ donné, on suppose qu'il est pertinent de représenter cette mesure par une variable aléatoire $Y = \theta x^2 + aZ$, $a$ connu, $\theta$ un paramètre réel inconnu et $Z$ une variable aléatoire normale centrée réduite.

## Estimation du paramètre $\theta$

Pour estimer le paramètre $\theta$, on fait $n(n \ge 1)$ essais indépendants avec des doses de l’agent $A$ notées $X_1, \ldots X_n$. De $Y$, on extrait donc un échantillon aléatoire bernoullien $\underline{Y}_{n} = (Y_1 \ldots Y_n)$.

### Modèle statistique associé à $Y_n$

On pose le modèle statistique suivant à deux paramètres : 
\[( \mathbb{R}^n,  \otimes_{i=1}^{n} N(\theta x^2, a^2)_{(\theta, a) \in \mathbb{R}^{2} \times ]0;+\infty[})\]

Avec pour vraissemblance : 
\[L(Y_{\underline{X}_n}, \theta, a^2) = (2 \pi a^2)^{\frac{-n}{2}} \times e^{\frac{\sum_{i = 1}^{n} (Y_i - \theta_{i}^{2})^2}{2a^2}}\]
et 
\[ log L(Y_{\underline{X}_n}, \theta, a^2) ) = log(2\pi)^{\frac{-n}{2}} - \frac{n}{2} \ln x - \frac{\sum_{i=1}^{n} (Y_i - \theta_{i}^{2})^2}{2a^2}  = g(\theta, a^2)\]

**??attention est ce que les formules plus haut sont correctes, la prof ne semblait pas les valider : => regarder la photo de la prof??**

### Régularité du modèle $Y_n$

On pose $Z$ une variable variable aléatoire normale centrée réduite, tel qu'en utilisant les notations précédentes : $Z = \frac{Y - \theta x^2}{a}$.

Or on sait selon le théorème 1 du chapitre sur la régression linéaire que le modèle : $( \mathbb{R}^n,  \otimes_{i=1}^{n} N(\theta_0 + \theta_1 x^2, a^2)_{(\theta_0,\theta_1, a) \in \mathbb{R}^{3} \times ]0;+\infty[}) \space : (3)$ Et sachant $\theta_0 = 0$ et $x'=x^2$ on a : $(3) \Rightarrow ( \mathbb{R}^n,  \otimes_{i=1}^{n} N(\theta x^2, a^2)_{(\theta, a) \in \mathbb{R}^{2} \times ]0;+\infty[})$

Ainsi le modèle de $Y_n$, cité plus haut, est régulier.

### Calcul de la borne de Cramer-Rao pour $\theta$

Pour $\theta$ on a la borne de Cramer-Rao suivante :
\[I_{\underline{X}_n}(\theta)^{-1}= \frac{a^2}{nS^2_{\underline{X}_n}}\]

### Calcul de l'EMV $\hat{\theta}_n$

On a :

\[EMV \space \hat{\theta}_n = \frac{\sum_{i=1}^{n}(x_i^2 - \overline{x_n^2})(Y_n - Y_i)}{nS_{X_n}^2}\]

**??? Montrer que c'est une EMM e $\theta$???**

### Démonstration de $\hat{\theta}_n$ en tant qu'estimateur efficace de $\theta$

**??? Need help here ???**

### Identification de la loi de $\hat{\theta}_n$

On a $\hat{\theta}_n$ tel que : 
\[\hat{\theta}_n \leadsto N(\theta_1, \frac{a^2}{nS^2_{\underline{X}_n}})\]

### Calcul d'un intervalle de confiance ($IC$) de niveau $1-\alpha$ pour $\theta$

Soit l'intervalle de confiance ($IC$) de $\hat{\theta}_n$ tel que : 

**??IC de $\hat{\theta_n}$ et non $\theta$ ???**

\[IC^{1-\alpha}_{Y_{\underline{X}_{n}}}(\theta) =  \left[ \theta - Z_{1- \frac{\alpha}{2}} \sqrt{\frac{a^2}{nS^2_{\underline{X}_n}}} ; \theta + Z_{1- \frac{\alpha}{2}} \sqrt{\frac{a^2}{nS^2_{\underline{X}_n}}}  \right]\]

## Estimation ponctuelle du paramètre $\theta$

### Description des données

```{r 3_data_import, echo=FALSE, results='hide'}
# On importe les données avec les commandes suivantes
d3 <- read_delim("../data/donnees.exo3.csv", 
    delim = ";", escape_double = FALSE, locale = locale(decimal_mark = ","), 
    trim_ws = TRUE, show_col_types = FALSE)
d3 <- select(d3, x, y)

#https://bookdown.org/yihui/rmarkdown-cookbook/kable.html
kable(x=d3, col.names=c("eee","$\theta$"))
```

L'effectif des données est de `r dim(d3)[1]`.

La table suivante résume la dispersion de nos données :

```{r 3_data_description, echo=FALSE}
summary(d3)
```
**TODO : ne pas afficher output de la commande summary mais seulement ce qui nous interresse (ici moyenne)**
**TODO : la prof ne veut pas le summary, mais les données brutes avec une autre colonne : x2**

```{r 3_correlation, echo=FALSE, results='hide'}
d3 <- dplyr::mutate(d3, x2 = d3$x * d3$x)
# regression line (y~x)
Dr<-lm(formula = d3$y~d3$x2)
a_coeff <- round(Dr$coefficients[2], digits = 2)
b_coeff <- round(Dr$coefficients[1], digits = 2)
model<-paste0("Y = ", a_coeff,"x² + ", b_coeff)
```


Le graphique, ci-dessous illustre le modèle aléatoire suivant $Y = \theta x^2 + aZ$  soulignant la relation linéaire entre $Y$ et $x^2$, tel que $Y = ax² + b$ avec $a=$`r a_coeff` et $b=$`r b_coeff`.

**??? supprimer les estimations $a$ et $b$ ci dessus ??? non on peut laisser selon la prof, mais ajouter qu'ils ont été calculé avec Pearson**

```{r 3_graph, echo=FALSE, fig.asp = .63}
# http://www.sthda.com/english/wiki/correlation-test-between-two-variables-in-r#visualize-your-data-using-scatter-plots
library("ggpubr")
ggscatter(d3, x = "x2", y = "y", 
          add = "reg.line", conf.int = TRUE, 
          cor.coef = TRUE, cor.method = "pearson",
          title = model,
          xlab = "Agent A (x²)", ylab = "Espèce E (Y)")
```

### Calcul d'une estimation ponctuelle de $\theta$

Il a pu être défini que : 

**??? Pas certain : de Yxi et Yxn???**

\[\hat{\theta}_{1n} = \frac{\sum_{i=1}^{n}(x_i^2 - \overline{x_n^2})(Y_{x_i} - \overline{Y_{\underline{X}_n}})}{nS_{\underline{X}_n}^2}\]

Ainsi à partir de l'échantillon, comme on a :

\[nS_{\underline{X}_n}^2 = \sum_{i=1}^{n}(x^2 - \overline{x^2_n}) = 656,906\]
et
\[nS_{\underline{X}_n}^2 = \sum_{i=1}^{n}(x^2 - \overline{x^2_n})(Y_{x_i} - \overline{Y_{\underline{X}_n}}) = 501,653\]

On peut en déduire $\hat{\theta}_{1n}$, tel que : 
\[\hat{\theta}_{1n} = \theta = 0,7637\]

Par ailleurs, on obtient un écart résiduel non nul, en effet, on a :

\[\sum_{i=1}^{n} \tilde{e_i} = 2,7\]

### Calcul d'un intervalle de confiance ($IC$) de niveau 95%  pour $\theta$

\[ \left[ \theta - Z_{1- \frac{\alpha}{2}} \sqrt{\frac{a^2}{nS^2_{\underline{X}_n}}} ;  \theta + Z_{1- \frac{\alpha}{2}} \sqrt{\frac{a^2}{nS^2_{\underline{X}_n}}} \right]  \space : (3)\]

Or on support que l'écart-type ($a$) est tel que $a = 0,5$, ainsi :

\[(3) \space \Leftrightarrow \left[ 0,7637 - 1,96 \times \sqrt{\frac{0,5^2}{656,906}} ; 0,7637 + 1,96 \times \sqrt{\frac{0,5^2}{656,906}}
 \right]\]

\[(3) \space \Leftrightarrow \left[ 0,7254 ; 0,8019 \right]\]


### Evaluation d'une évolution significative de $\theta$

On ne souhaite ici évaluer une croissance ou une décroissance, de $\theta$ ; mais seulement savoir s'il y a une différence.

Ainsi, on souhaite savoir si l'on peut accepter au seuil de 5% l'hypothèse $H_1 : \theta = \theta_{passé} \Leftrightarrow H_0 : \theta = 0,9$ contre $H_1 : \theta \ne 0,9$.

#### Test d'hypothèses

\[W^\alpha_{Y_{\underline{X}_n}}(\theta) = \left\{ \mid \hat{\theta}_n - 0,9 \mid > Z_{1- \frac{\alpha}{2}} \sqrt{\frac{a^2}{nS^2_{\underline{X}_n}}} \right\} \space : (4)\]

\[(4) \space \Leftrightarrow W^\alpha_{Y_{\underline{X}_n}}(\theta) = \left\{ \mid \hat{\theta}_n - 0,9 \mid > 1,96 \times \sqrt{\frac{0,5^2}{656,906}} \right\}\]

\[(4) \space \Leftrightarrow W^\alpha_{Y_{\underline{X}_n}}(\theta) = \left\{ \mid \hat{\theta}_n - 0,9 \mid > 0,038 \right\}\]

#### Observations

On observe :

\[\mid \hat{\theta}_n - 0,9 \mid = \mid 0,7637 - 0,9 \mid = \mid -0.1363 \mid = 0.1363 \space : (5)\]
\[(5) \space \Leftrightarrow \mid \hat{\theta}_n - 0,9 \mid \in W^\alpha_{Y_{\underline{X}_n}}\]

#### Décision

On accepte $H_1$, au seuil de 5%.

#### Conlcusion

On en conclue que la valeur du paramètre $\theta$ a évolu significativement par rapport aux mesures précédentes.
