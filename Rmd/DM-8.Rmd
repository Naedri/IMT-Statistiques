---
title: "UE Probabilité et Statistique - Mathématiques"
subtitle: "Devoir Maison n°8"
author: "Vincent Escoffier, Adrien Jallais, Théo Martel, Louis Muzellec."
place: "IMT-Atlantique - FIL A2"
date: "`r format(Sys.time(), '%d %B %Y')`"
knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding, output_dir = "../output") })
output:
  pdf_document: 
    latex_engine: xelatex  # More modern PDF typesetting engine
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE, tidy.opts = list(width.cutoff = 79),
  tidy = TRUE, fig.width = 6, fig.height = 6,
  warning = FALSE, message = FALSE
)
```

## Préparation de l'environnement

R et Rstudio seront utilisés pour la rédaction de ce DM, ainsi que les packages suivants :

```{r packages_loading, results='hide'}
library(readr)
library(dplyr)
library(ggplot2)
```

\newpage

# Exercice 1

```{r 1_cleaning, echo=FALSE, results='hide'}
rm(list = ls(all = TRUE))
data.frame(unlist("all"))
```

## Contexte

Soit $X$, la variable aléatoire représentant le nombre d'accidents par assuré. $X$ est une variables aléatoire discrète. Il est admis que l'occurence des sinistres $X$ suit une loi de Poisson pour laquelle on recherche le paramètre inconnu $\lambda$.
Le modèle d'échantillonage de nos données est le suivant : $(\mathbb{N}, (\mathscr{P}_{\lambda})_{\lambda>0})^{n}$.

### Description des données

```{r 1_data_import, echo=FALSE, results='hide'}
# On importe les données avec la commande suivante
d1 <- read_delim("../data/donnees.exo1.csv", 
    delim = ";", escape_double = FALSE, trim_ws = TRUE, show_col_types = FALSE)
```

L'effectif de l'échantillon est de `r dim(d1)[1]`. Celui-ci peut donc être considéré de grande taille.

Les indicateurs et le graphe suivant résument la dispersion de nos données :

```{r 1_data_description, echo=FALSE, fig.asp = .63}
summary(d1$sinistre)
ggplot(d1, aes(x=sinistre)) + geom_bar()
```

**TODO : ne pas afficher output de la commande summary mais seulement ce qui nous interresse (ici moyenne)**

**??? verifier xbar et n * xbar**

A partir de $\overline{X} =$ `r mean(d1$sinistre)`, on a $n \overline{X}_{n} =$ `r dim(d1)[1]*mean(d1$sinistre)`.

## Intervalle de confiance ($IC$) asymptotique pour $\lambda$

**??? que décidez vous ? prendre choix 1 ou choix 2 ? Adrien préfère choix 2**

### choix1
Comme la variable aléatoire X suit une loi de Poisson de paramètre $\lambda$ et que notre effectif d'échantillon n est grand, on utilise la fonction pivotale asymptotique : 

\[\frac{\sqrt{n}(\overline{X}_n - \lambda)}{\sqrt{\overline{X}_n}} \leadsto N(0,1)\]
### choix2
Selon une estimation ds intervalles de confiances sur le modèle d'échantillonngage de lois de Poissons : étude et estimations de $\lambda$ (p45)
Comme le modèle est discret età distance finie, on peut calculer des intervalles de confiances par excès en utilisant la relation 

\[F_{n \underline{X}_n (k) = P (\{Y_n > 2n \lambda\}))} \leadsto \chi^2_{2(k+1)]} \]

### après
Ainsi, on peut en déduire un intervalle de confiance ($IC$) asymptotique.

\[IC^{1-\alpha \text{ asymp }}_{\underline{X}_{n}}(\lambda) =  \left[\overline{X}_{n} - Z_{1 - \frac{\alpha}{2}} \times \sqrt{\frac{\overline{X}_{n}}{n}} \space ; \space  
\overline{X}_{n} + Z_{1 - \frac{\alpha}{2}} \times \sqrt{\frac{\overline{X}_{n}}{n}}
\space \right] \space\]

### 1. Calcul d'un interval de confiance asymptotique unilatéral gauche de niveau 95% pour $\lambda$ ($IC_g$)

On obtient un $IC$ tel que : 

\[IC^{1-\alpha \text{ asymp }}_{\underline{X}_{n}}(\lambda) =  \left[\overline{X}_{n} - Z_{1 - \frac{\alpha}{2}} \times \sqrt{\frac{\overline{X}_{n}}{n}} <  \lambda \right] \space : (1)\]
\[(1) \space \Leftrightarrow IC^{0,95 \text{ asymp }}_{\underline{X}_{n}}(\lambda) = \left[0,543 - Z_{1 - \frac{0,05}{2}} \times \sqrt{\frac{0,543}{35}} <  \lambda \right] \]
\[(1) \space \Leftrightarrow IC^{0,95 \text{ asymp }}_{\underline{X}_{n}}(\lambda) = \left[0,543 - 1,96 \times \sqrt{\frac{0,543}{35}} <  \lambda \right] \]
\[(1) \space \Leftrightarrow IC^{0,95 \text{ asymp }}_{\underline{X}_{n}}(\lambda) = \left[0,298 <  \lambda \right] \]

### 2. Calcul d'un interval de confiance asymptotique unilatéral droit de niveau 95% pour $\lambda$ ($IC_d$)

On obtient un  tel que : 

\[IC^{1+\alpha \text{ asymp }}_{\underline{X}_{n}}(\lambda) =  \left[\overline{X}_{n} + Z_{1 - \frac{\alpha}{2}} \times \sqrt{\frac{\overline{X}_{n}}{n}} >  \lambda \right] \space : (2)\]
\[(2) \space \Leftrightarrow IC^{0,95 \text{ asymp }}_{\underline{X}_{n}}(\lambda) = \left[0,543 + Z_{1 - \frac{0,05}{2}} \times \sqrt{\frac{0,543}{35}} >  \lambda \right] \]
\[(2) \space \Leftrightarrow IC^{0,95 \text{ asymp }}_{\underline{X}_{n}}(\lambda) = \left[0,543 + 1,96 \times \sqrt{\frac{0,543}{35}} >  \lambda \right] \]
\[(2) \space \Leftrightarrow IC^{0,95 \text{ asymp }}_{\underline{X}_{n}}(\lambda) = \left[0,787 >  \lambda \right] \]

<!-- TODO : Commenter ces observations -->

## Peut-on accepter l’hypothèse que $\lambda = 1$ ? 

### Test d'hypothèses

On pose $H_0 : \lambda = 1$ et $H_1 : \lambda \ne 1$.

### Observations

On a $\lambda \notin  IC_g$ et $\lambda \notin  IC_d$, autrement dit $\lambda \notin \left[0.298;0.787 \right]$ .

### Décision 

On rejette $H_0$.

### Conclusion 

Par conséquent, on a $\lambda \ne 1$.

### Commentaires

On peut vérifer cette négation, avec l'estimateur $W^{-\alpha}_{\underline{X}_{n}}(\lambda)$ de la manière suivante  : 

\[W^{\alpha}_{\underline{X}_{n}}(\lambda) = \left[ \frac{\underline{X}_{n}}{\overline{X}_{n}} < a_{\alpha} \right]  \space \text{ ou } \space  W^{\alpha}_{\underline{X}_{n}}(\lambda) = \left[ \overline{X}_{n} > b_{\alpha} \right]\]
\[P_{\lambda=1} (W^{-\alpha}_{\underline{X}_{n}}(\lambda)) \le \alpha \space \text{ et } \space P_{\lambda \ne 1} (W^{\alpha}_{\underline{X}_{n}}(\lambda)) \ge \alpha\]

\newpage

# Exercice 2

```{r 2_cleaning, echo=FALSE, results='hide'}
rm(list = ls(all = TRUE))
data.frame(unlist("all"))
```

## Contexte

Soit $X$, une variable aléatoire discrète représentant le nombre de pièces défectueuses par échantillon (représentée par une commande ou un lot). Les pièces peuvent être soient défectueuses, soient fonctionnelles. Notre échantillonage est donc extrait d'une épreuve de Bernouilli. La taille de l'échantillon est grande : $n > 100 \text{ avec } n = 140$.

On souhaite savoir si le client acceptera cet echantillon, et pour cela il faut qu'il contienne au moins 120 composants fonctionnels.

## Description du modèle de données

Notre échantillonnage aléatoire est simple tel que : $X_{n} = (X_{i})_{1 \le i \le n}$ avec le modèle suivant : $({0,1}(B(1,p)_{p})_{p \in [0,1]})$ sachant $p = 10\% = 0,1$.

On va comparer ce paramètre avec une estimation ponctuelle, afin de savoir si l'affirmation du fabricant est vraie. Pour cela nous allons réaliser deux tests : le premier du point de vue du fabricant ($TH_1$), le second du point de vue du client ($TH_2$).

## Observation ponctuelle

Dans notre observation ponctuelle (lot), on a observé que la proportion de pièces défectueuses est de `r 12/140` (`= 12/140`).

## Point de vue du fabricant ($TH_1$)

### Test d'hypothèses

\[H_0 : p_0 \le 0,1 \text{ contre } H_1 : p_0 > 0,1\]

\[W^{\alpha \text{ asymp }}_{X_n}(p) = \left\{ \frac{\underline{X}_{n}}{\overline{X}_{n}} > p + \frac{Z_{1-\alpha}}{\sqrt{n}} \times \sqrt{p(1-p)} \right\} \space : (3)\]
\[(3) \space \Leftrightarrow W^{0,05 \text{ asymp }}_{140}(p) = \left\{ \frac{\underline{X}_{n}}{\overline{X}_{n}} > 0,1 + \frac{1,96}{\sqrt{140}} \times \sqrt{0,1(1-0,1)} \right\} \]
\[(3) \space \Leftrightarrow W^{0,05 \text{ asymp }}_{140}(p) = \left\{ \frac{\underline{X}_{n}}{\overline{X}_{n}} > 0,1496 \right\} \]

### Observations

\[\frac{\underline{X}_{n}}{\overline{X}_{n}} = 0,0857 \notin W^{\alpha \text{ asymp }}_{X_n}(p)\]

### Décision

Pour le $TH_1$, on ne rejette pas l'hypothèse $H_0$ jusqu'à preuve du contraire.

### Conlcusion

Jusqu'à preuve du contraire, le client acceptera le lot.

## Point de vue du client ($TH_2$)

### Test d'hypothèses

\[H_0 : p_0 \ge 0,1 \text{ contre } H_1 : p_0 < 0,1\]

\[W^{\alpha \text{ asymp }}_{X_n}(p) = \left\{ \frac{\underline{X}_{n}}{\overline{X}_{n}} > p - \frac{Z_{1-\alpha}}{\sqrt{n}} \times \sqrt{p(1-p)} \right\} \space : (3)\]
\[(3) \space \Leftrightarrow W^{0,05 \text{ asymp }}_{140}(p) = \left\{ \frac{\underline{X}_{n}}{\overline{X}_{n}} > 0,1 - \frac{1,96}{\sqrt{140}} \times \sqrt{0,1(1-0,1)} \right\} \]
\[(3) \space \Leftrightarrow W^{0,05 \text{ asymp }}_{140}(p) = \left\{ \frac{\underline{X}_{n}}{\overline{X}_{n}} > 0,0503 \right\} \]

### Observations

\[\frac{\underline{X}_{n}}{\overline{X}_{n}} = 0,0857 \notin W^{\alpha \text{ asymp }}_{X_n}(p)\]

### Décision

Pour le $TH_2$, on accepte donc $H_0$.

### Conlcusion

Jusqu'à preuve du contraire, le client n'acceptera pas le lot. **??Problème de formulation ou de conclusion -> à vérifier??**

## Commentaires

L'acceptation du lot a été évaluée depuis les points de vues des deux parties.

**On se place du point de vue du client, il ne faudrait donc pas tester $TH_2$ mais seulement $TH_1$. En effet, en se placant du côté du client, on souhaite seulement évaluer ce que craint le client de rejeter à tord.**
**On a réalisé deux tests, si ilssont contradictaatoires => prendre le test du point de vue client.**

**??? TODO : vérifier la formulation des deux tests, avec le livret de cours module 2 (page 62).????**

\newpage

# Exercice 3

**LA PROF VEUT QUASI LA MEME CHOSE QUE L'EXO FAIT EN COURS (feuille donnée au dernier cours sur la regression)**

```{r 3_cleaning, echo=FALSE, results='hide'}
rm(list = ls(all = TRUE))
data.frame(unlist("all"))
```

## Contexte

Nous introduisons les variables $x$, $A$, $S$, $E$, $Y$, $\theta$, et $Z$ comme suit : 
Une expérience chimique consiste à ajouter une dose $x$ d'un agent $A$ dans une solution $S$. Après réaction, on mesure la quantité d'une espèce $E$. Pour $x$ donné, on suppose qu'il est pertinent de représenter cette mesure par une variable aléatoire $Y = \theta x^2 + aZ$, $a$ connu, $\theta$ un paramètre réel inconnu et $Z$ une variable aléatoire normale centrée réduite.

## Estimation du paramètre $\theta$

Pour estimer le paramètre $\theta$, on fait $n(n \ge 1)$ essais indépendants avec des doses de l’agent $A$ notées $X_1, \ldots X_n$. De $Y$, on extrait donc un échantillon aléatoire bernoullien $Y_n = (Y_1 \ldots Y_n)$.

### Modèle statistique associé à $Y_n$

On pose le modèle statistique suivant à deux paramètres : 
\[( \mathbb{R}^n,  \otimes_{i=1}^{n} N(\theta x^2, a^2)_{(\theta, a) \in \mathbb{R}^{2} \times ]0;+\infty[})\]

Avec pour vraissemblance : 
\[L(Y_{\underline{X}_n}, \theta, a^2) = (2 \pi a^2)^{\frac{-n}{2}} \times e^{\frac{\sum_{i = 1}^{n} (Y_i - \theta_{i}^{2})^2}{2a^2}}\]
et 
\[ log L(Y_{\underline{X}_n}, \theta, a^2) ) = log(2\pi)^{\frac{-n}{2}} - \frac{n}{2} \ln x - \frac{\sum_{i=1}^{n} (Y_i - \theta_{i}^{2})^2}{2a^2}  = g(\theta, a^2)\]

**??attention est ce que les formules plus haut sont correctes, la prof ne semblait pas les valider : => regarder la photo de la prof??**

### Régularité du modèle $Y_n$

On pose $Z$ une variable variable aléatoire normale centrée réduite, tel qu'en utilisant les notations précédentes : $Z = \frac{Y - \theta x^2}{a}$.

Or on sait selon le théorème 1 du chapitre sur la régression linéaire que le modèle : $( \mathbb{R}^n,  \otimes_{i=1}^{n} N(\theta_0 + \theta_1 x^2, a^2)_{(\theta_0,\theta_1, a) \in \mathbb{R}^{3} \times ]0;+\infty[}) \space : (3)$ Et sachant $\theta_0 = 0$ et $x'=x^2$ on a : $(3) \Rightarrow ( \mathbb{R}^n,  \otimes_{i=1}^{n} N(\theta x^2, a^2)_{(\theta, a) \in \mathbb{R}^{2} \times ]0;+\infty[})$

Ainsi le modèle de $Y_n$, cité plus haut, est régulier.

### Calcul de la borne de Cramer-Rao pour $\theta$

Pour $\theta$ on a la borne de Cramer-Rao suivante :
\[I_{\underline{X}_n}(\theta)^{-1}= \frac{a^2}{nS^2_{\underline{X}_n}}\]

### Calcul de l'EMV $\hat{\theta}_n$

On a :

\[EMV \space \hat{\theta}_n = \frac{\sum_{i=1}^{n}(x_i^2 - \overline{x_n^2})(Y_n - Y_i)}{nS_{X_n}^2}\]

**??? Montrer que c'est une EMM e $\theta$???**

### Démonstration de $\hat{\theta}_n$ en tant qu'estimateur efficace de $\theta$

**??? Need help here ???**

### Identification de la loi de $\hat{\theta}_n$

On a $\hat{\theta}_n$ tel que : 
\[\hat{\theta}_n \leadsto N(\theta_1, \frac{a^2}{nS^2_{\underline{X}_n}})\]

### Calcul d'un intervalle de confiance ($IC$) de niveau $1-\alpha$ pour $\theta$

Soit l'intervalle de confiance ($IC$) de $\hat{\theta}_n$ tel que : 

**??IC de $\hat{\theta_n}$ et non $\theta$ ???**

\[IC^{1-\alpha}_{Y_{\underline{X}_{n}}}(\theta) =  \left[ \theta - Z_{1- \frac{\alpha}{2}} \sqrt{\frac{a^2}{nS^2_{\underline{X}_n}}} ; \theta + Z_{1- \frac{\alpha}{2}} \sqrt{\frac{a^2}{nS^2_{\underline{X}_n}}}  \right]\]

**TODO : Mettre à jour les intervalles avec ';' et non ','**

## Estimation ponctuelle du paramètre $\theta$

### Description des données

```{r 3_data_import, echo=FALSE, results='hide'}
# On importe les données avec les commandes suivantes
d3 <- read_delim("../data/donnees.exo3.csv", 
    delim = ";", escape_double = FALSE, locale = locale(decimal_mark = ","), 
    trim_ws = TRUE, show_col_types = FALSE)
d3 <- select(d3, x, y)
```

L'effectif des données est de `r dim(d3)[1]`.

La table suivante résume la dispersion de nos données :

```{r 3_data_description, echo=FALSE}
summary(d3)
```
**TODO : ne pas afficher output de la commande summary mais seulement ce qui nous interresse (ici moyenne)**
**TODO : la prof ne veut pas le summary, mais les données brutes avec une autre colonne : x2**

```{r 3_correlation, echo=FALSE, results='hide'}
d3 <- dplyr::mutate(d3, x2 = d3$x * d3$x)
# regression line (y~x)
Dr<-lm(formula = d3$y~d3$x2)
a_coeff <- round(Dr$coefficients[2], digits = 2)
b_coeff <- round(Dr$coefficients[1], digits = 2)
model<-paste0("Y = ", a_coeff,"x² + ", b_coeff)
```


Le graphique, ci-dessous illustre le modèle aléatoire suivant $Y = \theta x^2 + aZ$  soulignant la relation linéaire entre $Y$ et $x^2$, tel que $Y = ax² + b$ avec $a=$`r a_coeff` et $b=$`r b_coeff`.

**??? supprimer les estimations $a$ et $b$ ci dessus ??? non on peut laisser selon la prof, mais ajouter qu'ils ont été calculé avec Pearson**

```{r 3_graph, echo=FALSE, fig.asp = .63}
# http://www.sthda.com/english/wiki/correlation-test-between-two-variables-in-r#visualize-your-data-using-scatter-plots
library("ggpubr")
ggscatter(d3, x = "x2", y = "y", 
          add = "reg.line", conf.int = TRUE, 
          cor.coef = TRUE, cor.method = "pearson",
          title = model,
          xlab = "Agent A (x²)", ylab = "Espèce E (Y)")
```

### Calcul d'une estimation ponctuelle de $\theta$

Il a pu être défini que : 

**??? Pas certain : de Yxi et Yxn???**

\[\hat{\theta}_{1n} = \frac{\sum_{i=1}^{n}(x_i^2 - \overline{x_n^2})(Y_{x_i} - \overline{Y_{\underline{X}_n}})}{nS_{\underline{X}_n}^2}\]

Ainsi à partir de l'échantillon, comme on a :

\[nS_{\underline{X}_n}^2 = \sum_{i=1}^{n}(x^2 - \overline{x^2_n}) = 656,906\]
et
\[nS_{\underline{X}_n}^2 = \sum_{i=1}^{n}(x^2 - \overline{x^2_n})(Y_{x_i} - \overline{Y_{\underline{X}_n}}) = 501,653\]

On peut en déduire $\hat{\theta}_{1n}$, tel que : 
\[\hat{\theta}_{1n} = \theta = 0,7637\]

Par ailleurs, on obtient un écart résiduel non nul, en effet, on a :

\[\sum_{i=1}^{n} \tilde{e_i} = 2,7\]

### Calcul d'un intervalle de confiance ($IC$) de niveau 95%  pour $\theta$

\[ \left[ \theta - Z_{1- \frac{\alpha}{2}} \sqrt{\frac{a^2}{nS^2_{\underline{X}_n}}} ;  \theta + Z_{1- \frac{\alpha}{2}} \sqrt{\frac{a^2}{nS^2_{\underline{X}_n}}} \right]  \space : (3)\]

Or on support que l'écart-type ($a$) est tel que $a = 0,5$, ainsi :

\[(3) \space \Leftrightarrow \left[ 0,7637 - 1,96 \times \sqrt{\frac{0,5^2}{656,906}} ; 0,7637 + 1,96 \times \sqrt{\frac{0,5^2}{656,906}}
 \right]\]

\[(3) \space \Leftrightarrow \left[ 0,7254 ; 0,8019 \right]\]


### Evaluation d'une évolution significative de $\theta$

On ne souhaite ici évaluer une croissance ou une décroissance, de $\theta$ ; mais seulement savoir s'il y a une différence.

Ainsi, on souhaite savoir si l'on peut accepter au seuil de 5% l'hypothèse $H_1 : \theta = \theta_{passé} \Leftrightarrow H_0 : \theta = 0,9$ contre $H_1 : \theta \ne 0,9$.

#### Test d'hypothèses

\[W^\alpha_{Y_{\underline{X}_n}}(\theta) = \left\{ \mid \hat{\theta}_n - 0,9 \mid > Z_{1- \frac{\alpha}{2}} \sqrt{\frac{a^2}{nS^2_{\underline{X}_n}}} \right\} \space : (4)\]

\[(4) \space \Leftrightarrow W^\alpha_{Y_{\underline{X}_n}}(\theta) = \left\{ \mid \hat{\theta}_n - 0,9 \mid > 1,96 \times \sqrt{\frac{0,5^2}{656,906}} \right\}\]

\[(4) \space \Leftrightarrow W^\alpha_{Y_{\underline{X}_n}}(\theta) = \left\{ \mid \hat{\theta}_n - 0,9 \mid > 0,038 \right\}\]

#### Observations

On observe :

\[\mid \hat{\theta}_n - 0,9 \mid = \mid 0,7637 - 0,9 \mid = \mid -0.1363 \mid = 0.1363 \space : (5)\]
\[(5) \space \Leftrightarrow \mid \hat{\theta}_n - 0,9 \mid \in W^\alpha_{Y_{\underline{X}_n}}\]

#### Décision

On accepte $H_1$, au seuil de 5%.

#### Conlcusion

On en conclue que la valeur du paramètre $\theta$ a évolu significativement par rapport aux mesures précédentes.
